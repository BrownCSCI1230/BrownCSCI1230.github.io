<!DOCTYPE html>
    <html lang="en">
      <head><link rel="stylesheet" type="text/css" href="/assets/index.a2008b3d.css">
        <meta charset="UTF-8">
        <title>Project 4 | CSCI 1230</title>
        <meta name="description" content="We teach computer graphics!">
        <meta name="keywords" content="Computer Science, Computer Graphics, CS 1230, CSCI 1230, Brown University, Providence">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <!-- Google tag (gtag.js) -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-263NEZCW0C"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-263NEZCW0C');
        </script>
      </head>
      <body>
        <div id="root">
          <nav id="nav-bar"><div id="nav-bar-inner"><a id="logo" class="no-select" href="/" aria-label="home" style="--duration:450ms"><div id="logo-box-1"></div><div id="logo-box-2"></div><div id="logo-box-3"></div><div id="logo-box-4"></div><div id="logo-box-5"></div><div id="logo-box-6"></div></a><div id="nav-items"><div id="nav-items-inner"><a href="/" class="nav-item">Home</a><a href="/docs" class="nav-item">Docs</a><a href="/lectures" class="nav-item">Lectures</a><a href="/labs" class="nav-item">Labs</a><a href="/projects" class="nav-item">Projects</a></div></div></div></nav><div id="page" class=""><nav class="toc"><ol class="toc-level toc-level-1"><li class="toc-item toc-item-h1"><a class="toc-link toc-link-h1" href="#project-4-antialias">Project 4: Antialias</a><ol class="toc-level toc-level-2"><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#introduction">Introduction</a></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#requirements">Requirements</a><ol class="toc-level toc-level-3"><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#supersampling">Supersampling</a><ol class="toc-level toc-level-4"><li class="toc-item toc-item-h4"><a class="toc-link toc-link-h4" href="#regular-grid-sampling">Regular Grid Sampling</a></li><li class="toc-item toc-item-h4"><a class="toc-link toc-link-h4" href="#random-sampling">Random Sampling</a></li><li class="toc-item toc-item-h4"><a class="toc-link toc-link-h4" href="#stratified-sampling">Stratified Sampling</a></li><li class="toc-item toc-item-h4"><a class="toc-link toc-link-h4" href="#adaptive-sampling-extra-credit">Adaptive Sampling (Extra Credit)</a></li></ol></li><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#texture-filtering">Texture Filtering</a><ol class="toc-level toc-level-4"><li class="toc-item toc-item-h4"><a class="toc-link toc-link-h4" href="#bilinear-filtering">Bilinear Filtering</a></li><li class="toc-item toc-item-h4"><a class="toc-link toc-link-h4" href="#mipmapping">Mipmapping</a><ol class="toc-level toc-level-5"><li class="toc-item toc-item-h5"><a class="toc-link toc-link-h5" href="#downsampling">Downsampling</a></li><li class="toc-item toc-item-h5"><a class="toc-link toc-link-h5" href="#mipmap-generation">Mipmap Generation</a></li><li class="toc-item toc-item-h5"><a class="toc-link toc-link-h5" href="#determining-mipmap-level-at-render-time">Determining Mipmap Level at Render Time</a></li><li class="toc-item toc-item-h5"><a class="toc-link toc-link-h5" href="#trilinear-filtering">Trilinear Filtering</a></li></ol></li></ol></li><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#glm-library-functions">GLM Library Functions</a></li></ol></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#codebase--design">Codebase &amp; Design</a></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#scenes-viewer">Scenes Viewer</a></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#ta-demos">TA Demos</a><ol class="toc-level toc-level-3"><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#instructions-for-running">Instructions for Running</a></li></ol></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#grading">Grading</a></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#extra-credit">Extra Credit</a></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#tips--hints">Tips &amp; Hints</a></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#milestones">Milestones</a></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#submission">Submission</a></li></ol></li></ol></nav><main>
<!-- -->
<h1 id="project-4-antialias"><a href="#project-4-antialias">Project 4: Antialias</a></h1>
<p><a href="https://classroom.github.com/a/q5yySIHP" target="_blank" rel="noopener noreferrer">Github Classroom assignment</a> (same assignment as before)</p>
<p>You can find the section handout for this project <a href="/projects/ray/3-algo">here</a>.</p>
<div class="warning-callout callout"><p>Please read this project handout <strong>before</strong> going to algo section!</p></div>
<h2 id="introduction"><a href="#introduction">Introduction</a></h2>
<p>By now, you have a powerful ray tracer in your hands, able to produce beautiful renders complete with shadows, textures, and even recursive reflections!
At some point though, something may have bothered you about the produced images.</p>
<figure id="figure-1" class="image-wrapper"><div class="image-grid" style="--target-width:20%"><a href="/projects/ray/3/jaggies.png" target="_blank" rel="noopener noreferrer"><img src="/projects/ray/3/jaggies.png" alt="TODO"/></a></div><figcaption><strong>Figure 1: </strong>Jaggies, ugh...</figcaption></figure>
<p>Often referred to as “jaggies”, this is an instance of the signal processing phenomenon known as aliasing. In this case, our ray tracer is not sufficiently sampling these object silhouettes, causing an implicitly smooth edge to appear in (i.e. alias to) a jagged, stair-step pattern.</p>
<p>Aliasing can also occur on textured objects, like this:</p>
<figure id="figure-2" class="image-wrapper"><div class="image-grid" style="--target-width:20%"><a href="/projects/ray/3/checkerboard_aliased.png" target="_blank" rel="noopener noreferrer"><img src="/projects/ray/3/checkerboard_aliased.png" alt="TODO"/></a></div><figcaption><strong>Figure 2: </strong>A very poor representation of a checkerboard pattern, tbh...</figcaption></figure>
<h2 id="requirements"><a href="#requirements">Requirements</a></h2>
<p>For this project, you will incorporate the following antialiasing techniques into your ray tracer:</p>
<h3 id="supersampling"><a href="#supersampling">Supersampling</a></h3>
<p>Super-sampling aims to mitigate aliasing by sampling each pixel at multiple locations. This leads us to two questions: Where should we sample from? How many samples should we use?</p>
<h4 id="regular-grid-sampling"><a href="#regular-grid-sampling">Regular Grid Sampling</a></h4>
<p>The simplest approach is to sample the pixel in a regular grid pattern. For example, if we want to take 9 samples per pixel, we can sample at the centers of each cell of a 3x3 grid, like this:</p>
<figure id="figure-3" class="image-wrapper"><div class="image-grid" style="--target-width:20%"><a href="/projects/ray/3/supersampling_grid.png" target="_blank" rel="noopener noreferrer"><img src="/projects/ray/3/supersampling_grid.png" alt="TODO"/></a></div><figcaption><strong>Figure 3: </strong>Supersampling a pixel with a 3x3 regular grid pattern.</figcaption></figure>
<p>For this assignment, we only expect you to implement square sampling patterns (e.g. 1, 4, 9, 16, samples per pixel). If the <code>.ini</code> file for your scene specifies a non-square number of samples per pixel, it is fine to round up to the nearest square. However, you are welcome to experiment with other patterns, if you wish.</p>
<h4 id="random-sampling"><a href="#random-sampling">Random Sampling</a></h4>
<p>Regular grid sampling can lead to artifacts, since the sampling pattern is correlated with the pixel grid. An alternative is to sample uniformly at random within the pixel, like this:</p>
<figure id="figure-4" class="image-wrapper"><div class="image-grid" style="--target-width:20%"><a href="/projects/ray/3/supersampling_random.png" target="_blank" rel="noopener noreferrer"><img src="/projects/ray/3/supersampling_random.png" alt="TODO"/></a></div><figcaption><strong>Figure 4: </strong>Supersampling with 9 random samples per pixel.</figcaption></figure>
<p>Think about how you might produce such a uniform random sampling pattern. You&#x27;re welcome to use any random number generation library you like, such as the C++ standard library&#x27;s <code>&lt;random&gt;</code> header.</p>
<h4 id="stratified-sampling"><a href="#stratified-sampling">Stratified Sampling</a></h4>
<p>Random sampling trades off potential grid-based artifacts for noise. But purely random samples can be quite clumpy: some areas of the pixel are oversampled while others are undersampled, leading to more noise. Stratified sampling attempts to mitigate this problem by combining regular grid sampling with random sampling: it divides the pixel into a grid and takes one random sample within each grid cell. For example, if we want to take 9 samples per pixel, we can divide the pixel into a 3x3 grid, and take one random sample within each grid cell, like this:</p>
<figure id="figure-5" class="image-wrapper"><div class="image-grid" style="--target-width:20%"><a href="/projects/ray/3/supersampling_stratified.png" target="_blank" rel="noopener noreferrer"><img src="/projects/ray/3/supersampling_stratified.png" alt="TODO"/></a></div><figcaption><strong>Figure 5: </strong>Supersampling with 9 random samples distributed in a stratified 3x3 pattern.</figcaption></figure>
<p>As with regular grid sampling, it is fine to round up to the nearest square number of samples per pixel if the <code>.ini</code> file specifies a non-square number.</p>
<h4 id="adaptive-sampling-extra-credit"><a href="#adaptive-sampling-extra-credit">Adaptive Sampling (Extra Credit)</a></h4>
<p>You may notice that your runtime has significantly increased after implementing supersampling, since you&#x27;re tracing many more rays per pixel. You may also notice that you start getting diminishing returns from increasing the sampling rate: many pixels do just fine with 1-4 samples per pixel, and the more samples you add, the fewer pixels benefit from each added sample.</p>
<p>This observation suggests an optimization: we can <em>adaptively</em> choose how many samples to take per pixel, based on how much variation there is between samples in the pixel. For example, if a pixel covers a constant-color patch of the scene, we can probably get away with taking only 1 sample. But if a pixel falls on an edge or a patch of high-frequency texture, we may want to take more samples.</p>
<p>There are many ways to implement adaptive sampling. One simple approach is to take a small number of initial samples (e.g. 4), and compute the <a href="https://en.wikipedia.org/wiki/Variance" target="_blank" rel="noopener noreferrer">statistical variance</a> of those samples. If the variance is below some threshold, we can stop and use the average of those samples as the pixel color. If the variance is above the threshold, we can take more samples (e.g. 4 more), and repeat the process until we reach a maximum number of samples per pixel.</p>
<h3 id="texture-filtering"><a href="#texture-filtering">Texture Filtering</a></h3>
<p>Supersampling attempts to sample the image at a high enough rate that aliases don&#x27;t occur. But this is expensive, and sometimes its impossible (e.g sharp edges that introduce infinite frequency content). An alternate strategy is to get rid of frequency content in the image that we can&#x27;t reprsent with our sample budget. That&#x27;s hard to do in general, but it is (approximately) possible for textures.</p>
<p>In the previous project, when you looked up the texture value at an intersection point, you retrieved the texel (texture map pixel) that was closest to the intersection point. This is called nearest-neighbor sampling, and it can lead to aliasing artifacts when the texture is viewed at a distance or at a steep angle. For example:</p>
<figure id="figure-6" class="image-wrapper"><div class="image-grid" style="--target-width:20%"><a href="/projects/ray/3/nearest_sampling.jpg" target="_blank" rel="noopener noreferrer"><img src="/projects/ray/3/nearest_sampling.jpg" alt="TODO"/></a></div><figcaption><strong>Figure 6: </strong>Aliasing artifacts from nearest-neighbor texture sampling.</figcaption></figure>
<p>In this project, you&#x27;ll implement some better texture sampling techniques to reduce these artifacts.</p>
<h4 id="bilinear-filtering"><a href="#bilinear-filtering">Bilinear Filtering</a></h4>
<p>Bilinear filtering is a simple improvement over nearest-neighbor sampling. Instead of just taking the value of the nearest texel, we take a weighted average of the 4 nearest texels. This is equivalent to filtering the texture with a 2x2 triangle filter. Doing so results in improved image quality, like this:</p>
<figure id="figure-7" class="image-wrapper"><div class="image-grid" style="--target-width:20%"><a href="/projects/ray/3/bilinear_sampling.jpg" target="_blank" rel="noopener noreferrer"><img src="/projects/ray/3/bilinear_sampling.jpg" alt="TODO"/></a></div><figcaption><strong>Figure 7: </strong>Improved quality from bilinear texture filtering.</figcaption></figure>
<p>Here is the difference between the two:</p>
<figure id="figure-7" class="image-wrapper"><div class="image-grid" style="--target-width:20%"><a href="/projects/ray/3/bilinear_vs_nearest.gif" target="_blank" rel="noopener noreferrer"><img src="/projects/ray/3/bilinear_vs_nearest.gif" alt="Bilinear vs Nearest Neighbor gif"/></a></div><figcaption><strong>Figure 7: </strong>Bilinear vs Nearest Neighbor texture sampling</figcaption></figure>
<h4 id="mipmapping"><a href="#mipmapping">Mipmapping</a></h4>
<p>Bilinear filtering helps, but a fixed 2x2 filter window is not always enough. When a texture is viewed at a steep angle or from a distance, a pixel may cover many texels. In this case, we should be averaging over a larger area of the texture to minimize aliasing. Ideally, we would filter the texture with a filter whose size is proportional to the pixel&#x27;s footprint on the texture. However, doing so would be prohibitively expensive at render time. Instead, we can precompute a series of downsampled versions of the texture, called mipmaps (short for &quot;multum in parvo&quot;, Latin for &quot;many things in a small place&quot;). Each level of the mipmap is downsampled by a factor of 2 in each dimension. Then, at render time, we can choose the appropriate mipmap level(s) to sample from based on a pixel&#x27;s footprint on the texture.</p>
<p>Implementing mipmapping requires multiple steps, which we outline below.</p>
<h5 id="downsampling"><a href="#downsampling">Downsampling</a></h5>
<p>Generating mipmaps requires the ability to properly downsample an image. Thus, you&#x27;ll need to implement a function that can take an image and scale it down by an artbitrary factor, being sure to use a pre-filter which avoids introducing aliases. You should use a triangle filter for this purpose (though you can use better filters for extra credit), and you should implement it as a separable filter for efficiency.
Everything you need to know for this implementation has already been covered in great depth during the Sampling, reconstruction, &amp; antialiasing lectures.</p>
<div class="warning-callout callout"><details><summary><strong>Beware of losing image brightness:</strong></summary><p>Recall from lecture that downsampling by non-integer factors requires explicit normalization of the filter kernel. This is because the filter kernel will not be symmetric around the center pixel, and thus the sum of the weights will not be 1. You must explicitly normalize the weights to ensure that they sum to 1. This is also true for edge pixels, which will get darker if you don&#x27;t normalize.</p></details></div>
<p>Here&#x27;s an example of downsampling an image by a factor of 4 using a triangle filter:</p>
<figure id="figure-8.1" class="image-wrapper"><div class="image-grid" style="--target-width:auto"><a href="/projects/ray/3/cheese.png" target="_blank" rel="noopener noreferrer"><img src="/projects/ray/3/cheese.png" alt="Original image" style="width:auto;height:auto"/></a></div><figcaption><strong>Figure 8.1: </strong>Original image. (to scale)</figcaption></figure>
<figure id="figure-8.2" class="image-wrapper"><div class="image-grid" style="--target-width:auto"><a href="/projects/ray/3/down_scale_4.png" target="_blank" rel="noopener noreferrer"><img src="/projects/ray/3/down_scale_4.png" alt="Downsampled image" style="width:auto;height:auto"/></a></div><figcaption><strong>Figure 8.2: </strong>Downsampled by a factor of 4 using a triangle filter. (to scale)</figcaption></figure>
<h5 id="mipmap-generation"><a href="#mipmap-generation">Mipmap Generation</a></h5>
<p>Once you&#x27;ve implemented downsampling, you can generate mipmaps for every texture in your scene.</p>
<ul>
<li>You should generate mipmaps <strong>during scene loading</strong>, so that you don&#x27;t have to pay the cost of generating mipmaps at render time. In fact, you will lose efficiency points if you generate mipmaps at render time.</li>
<li>For each texture, generate all possible mipmap levels, starting at the original image size and going all the way down to a 1x1 image.</li>
<li>Since we&#x27;re doing offline rendering, we can trade some speed for quality. Thus, you should produce each mipmap level by downsampling from the original image, rather than downsampling the previous mipmap level by a factor of 2.</li>
</ul>
<p>Think about the way you&#x27;ll use these downscaled images in your raytracer, and choose an appropriate data structure to keep track of them.</p>
<p>Here&#x27;s an example of what a mipmap pyramid (i.e. the set of all mipmap levels for a given texture) might look like:</p>
<figure id="figure-9" class="image-wrapper"><div class="image-grid" style="--target-width:60%"><a href="/projects/ray/3/mip_pyramid_labeled.png" target="_blank" rel="noopener noreferrer"><img src="/projects/ray/3/mip_pyramid_labeled.png" alt="A mipmap pyramid"/></a></div><figcaption><strong>Figure 9: </strong>A mipmap pyramid, showing all levels of a mipmapped texture. (not to scale)</figcaption></figure>
<h5 id="determining-mipmap-level-at-render-time"><a href="#determining-mipmap-level-at-render-time">Determining Mipmap Level at Render Time</a></h5>
<p>When you sample from a mipmapped texture, you should determine which mip level to sample from. To do that, you must determine the pixel&#x27;s “footprint” upon the texture, i.e. how many texels are covered by the screen pixel through which the current ray was traced.
In lecture, we discussed how to do this using a bit of differential calculus; you&#x27;ll need to implement that approach here.</p>
<details><summary><strong>What about recursive rays?</strong></summary><p>Properly computing the texture footprint for a recursive ray (i.e. a ray that has been through at least one reflection or refraction bounce) requires tracking ray differentials through each bounce. This is an extra credit feature and is not required for this project (unless you are a 2230/1234 student). Instead, you&#x27;ll get full credit if you use the same footprint as the eye ray that generated the recursive ray.</p><div class="error-callout callout"><p>You will <strong>not</strong> receive full credit for using a constant footprint for recursive rays or for ignoring mipmaps altogether for recursive rays.</p></div></details>
<p>Recall that one of the steps in this process involves computing the derivatives of the <span class="math math-inline"><mjx-container className="MathJax" jax="SVG"><svg style="vertical-align:-0.566ex" xmlns="http://www.w3.org/2000/svg" width="5.158ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 2279.7 1000" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-1-TEX-I-1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-1-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-1-TEX-I-1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path><path id="MJX-1-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="28" xlink:href="#MJX-1-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(389,0)"><use data-c="1D462" xlink:href="#MJX-1-TEX-I-1D462"></use></g><g data-mml-node="mo" transform="translate(961,0)"><use data-c="2C" xlink:href="#MJX-1-TEX-N-2C"></use></g><g data-mml-node="mi" transform="translate(1405.7,0)"><use data-c="1D463" xlink:href="#MJX-1-TEX-I-1D463"></use></g><g data-mml-node="mo" transform="translate(1890.7,0)"><use data-c="29" xlink:href="#MJX-1-TEX-N-29"></use></g></g></g></svg></mjx-container></span> surface coordinates with respect to the object space intersection point <span class="math math-inline"><mjx-container className="MathJax" jax="SVG"><svg style="vertical-align:-0.439ex" xmlns="http://www.w3.org/2000/svg" width="1.446ex" height="1.457ex" role="img" focusable="false" viewBox="0 -450 639 644" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-2-TEX-B-1D429" d="M32 442L123 446Q214 450 215 450H221V409Q222 409 229 413T251 423T284 436T328 446T382 450Q480 450 540 388T600 223Q600 128 539 61T361 -6H354Q292 -6 236 28L227 34V-132H296V-194H287Q269 -191 163 -191Q56 -191 38 -194H29V-132H98V113V284Q98 330 97 348T93 370T83 376Q69 380 42 380H29V442H32ZM457 224Q457 303 427 349T350 395Q282 395 235 352L227 345V104L233 97Q274 45 337 45Q383 45 420 86T457 224Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D429" xlink:href="#MJX-2-TEX-B-1D429"></use></g></g></g></g></svg></mjx-container></span>. In algo section, you&#x27;ll work through the math to compute these derivatives for spheres. In this project, you&#x27;ll need to figure out the implementation of the corresponding derivatives for the other types of primitives supported by your raytracer (cubes, cones, and cylinders). You are welcome to use external resources to help you, provided you cite them in your submission. You might find online symbolic math calculators such as <a href="https://www.wolframalpha.com/" target="_blank" rel="noopener noreferrer">Wolfram Alpha</a> or <a href="https://www.symbolab.com/" target="_blank" rel="noopener noreferrer">Symbolab</a> helpful for working through the math.</p>
<h5 id="trilinear-filtering"><a href="#trilinear-filtering">Trilinear Filtering</a></h5>
<p>One downside of using a single mipmap level is that the transition between levels can be abrupt, leading to noticeable &#x27;seam&#x27; artifacts. For example, here&#x27;s the checkerboard floor scene from earlier, rendered with bilinear filtering and a single mipmap level:</p>
<figure id="figure-10" class="image-wrapper"><div class="image-grid" style="--target-width:60%"><a href="/projects/ray/3/mipmap_bilinear.png" target="_blank" rel="noopener noreferrer"><img src="/projects/ray/3/mipmap_bilinear.png" alt="TODO"/></a></div><figcaption><strong>Figure 10: </strong>Notice the seams where the mipmap level changes abruptly.</figcaption></figure>
<p>We can eliminate these artifacts by instead interpolating between two adjacent mipmap levels. This is called <strong>trilinear filtering</strong>, since it involves bilinear filtering in the two spatial dimensions, plus linear interpolation between the two mipmap levels.</p>
<p>When you compute the footprint of a pixel on the texture (based on the equations from lecture), you get a value in units of texels; taking the base 2 logarithm of that value gives you a floating point mipmap level. The integer part of that value tells you which two mipmap levels to interpolate between, and the fractional part tells you how to weight the two levels. For example, if the computed mipmap level is 3.2, you would bilinearly filter from mipmap levels 3 and 4, and weight them 0.8 and 0.2, respectively.</p>
<p>Here&#x27;s the improvement you can expect from trilinear filtering:</p>
<figure id="figure-11" class="image-wrapper"><div class="image-grid" style="--target-width:60%"><a href="/projects/ray/3/mipmap_trilinear.png" target="_blank" rel="noopener noreferrer"><img src="/projects/ray/3/mipmap_trilinear.png" alt="TODO"/></a></div><figcaption><strong>Figure 11: </strong>Trilinear filtering eliminates the seams between mipmap levels.</figcaption></figure>
<h3 id="glm-library-functions"><a href="#glm-library-functions">GLM Library Functions</a></h3>
<p>Please avoid using the following GLM functions, as we have covered how to implement them in class:</p>
<ul>
<li>
<p><code>glm::lookAt(eye, center, up)</code></p>
</li>
<li>
<p><code>glm::reflect(I, N)</code></p>
</li>
<li>
<p><code>glm::perspective(fovy, aspect, near, far)</code></p>
</li>
<li>
<p><code>glm::mix(x, y, a)</code></p>
</li>
<li>
<p><code>glm::distance(p1, p2)</code></p>
</li>
</ul>
<h2 id="codebase--design"><a href="#codebase--design">Codebase &amp; Design</a></h2>
<p>Your work on this project will extend your code from the Intersect and Illuminate projects; there is no additional stencil code.</p>
<p>As before, the structure of this project is entirely up to you: you can add new classes, files, etc.
However, you should not alter any command line interfaces we have implemented in the code base.</p>
<p>We provide all the rendered results of the scenes we have in the <code>scenefiles</code> folder under <code>antialias/required_outputs</code>, <code>antialias/optional_outputs</code>, and <code>antialias/extra_credit_outputs</code>.
They serve as references for you to check the correctness of your implementation.</p>
<div class="warning-callout callout"><p>You may notice that features like mipmapping and many other extra credit features are part of the config that is specified in the <code>QSettings</code> file,
which indicates that they should be able to be toggled on / off based on the input configuration. We expect your implementation to respect this behavior.</p><p>If you implement any additional extra credit feature that is not covered by the template config, make sure to rememeber adding the additional flag to
your <code>RayTracer::Config</code> and document it properly in your <code>README</code></p></div>
<div class="success-callout callout"><p>We also provide an automated script, <code>run-antialias.sh</code>, included in the stencil, to run your ray tracer on all required scenes for submission. This script is compatible with macOS, Linux, and <strong>Git Bash</strong> on Windows. To run it, make sure
you have built a <strong>Release</strong> version of your project in Qt, and then simply run:</p><pre class="language-sh"><code class="language-sh code-highlight"><span class="code-line">sh run-antialias.sh
</span></code></pre></div>
<h2 id="scenes-viewer"><a href="#scenes-viewer">Scenes Viewer</a></h2>
<p>To assist with creating and modifying scene files, we have made a web viewer called <a href="https://scenes.cs1230.graphics/" target="_blank" rel="noopener noreferrer">Scenes</a>. From this site, you are able to upload scenefiles or start from a template, modify properties, then download the scene JSON to render with your raytracer.</p>
<p>We hope that this is a fun and helpful tool as you implement the rest of the projects in the course which all use this scenefile format!</p>
<p>For more information, here is our published documentation for the <a href="/docs/scenefile-documentation">JSON scenefile format</a> and a <a href="/docs/scenes-tutorial">tutorial for using Scenes</a>.</p>
<h2 id="ta-demos"><a href="#ta-demos">TA Demos</a></h2>
<p>Demos of the TA solution are available <a href="https://drive.google.com/drive/folders/1cnW1zcrWts_R84Afiu7lHvBo1xYprLmV?usp=sharing" target="_blank" rel="noopener noreferrer">in this Google Drive folder</a>.</p>
<!-- -->
<div class="error-callout callout"><details><summary><strong>macOS Warning:</strong> &quot;____ cannot be opened because the developer cannot be verified.&quot;</summary><p>If you see this warning, <strong>don&#x27;t eject the disk image</strong>. You can allow the application to be opened from your system settings:</p><p>Settings &gt; Privacy &amp; Security &gt; Security &gt; &quot;____ was blocked from use because it is not from an identified developer.&quot; &gt; <strong>Click &quot;Allow Anyway&quot;</strong></p></details></div>
<h3 id="instructions-for-running"><a href="#instructions-for-running">Instructions for Running</a></h3>
<p>You can run the app from the command line with the same <code>.ini</code> filepath argument that you would use in QtCreator. <strong>You must put the executable inside of your build folder for this project in order to load the scenefiles correctly.</strong></p>
<p>On Mac:</p>
<p><code>open projects_antialias_&lt;min/max&gt;.app --args &lt;/absolute/filepath.ini&gt;</code></p>
<p>On Windows and Linux:</p>
<p><code>./projects_antialias_&lt;min/max&gt; &lt;/absolute/filepath.ini&gt;</code></p>
<h2 id="grading"><a href="#grading">Grading</a></h2>
<div class="error-callout callout"><p>For points deducted regarding software engineering/efficiency in your implementation of Project 2: Intersect and Project 3: Illuminate,
you will have the same points deducted again for this part of the project if these are not corrected.</p></div>
<p>This assignment is out of 100 points.</p>
<ul>
<li>Supersampling<!-- -->
<ul>
<li>Regular Grid Sampling <strong>(5 points)</strong></li>
<li>Random Sampling <strong>(4 points)</strong></li>
<li>Stratified Sampling <strong>(6 points)</strong></li>
</ul>
</li>
<li>Texture filtering<!-- -->
<ul>
<li>Bilinear Filtering <strong>(10 points)</strong></li>
<li>Image Downsampling <strong>(25 points)</strong></li>
<li>Mip-map Generation <strong>(5 points)</strong></li>
<li>Determining Mip-map Levels <strong>(20 points)</strong></li>
<li>Trilinear Filtering <strong>(5 points)</strong></li>
</ul>
</li>
<li>Software engineering, efficiency, &amp; stability <strong>(20 points)</strong></li>
</ul>
<div class="warning-callout callout"><p>Remember that filling out the <code>submission-antialias.md</code> template is critical for grading. You will be penalized if you do not fill it out.</p><div class="error-callout callout"><p>We have made some updates to the Antialias submission template since the Ray projects were first released. Please refer to EdStem for the latest instructions on how to get the updated template and scenefiles.</p></div></div>
<h2 id="extra-credit"><a href="#extra-credit">Extra Credit</a></h2>
<div class="warning-callout callout"><p>To earn credit for extra features, you must design test cases that demonstrate that they work. These test cases should be <em>sufficient</em>; for example:</p><ul>
<li>If you implement a feature that has some parameter, you should have multiple test cases for different values of the parameter.</li>
<li>If you implement a feature that has some edge cases, you should have test cases that demonstrate that the edge cases work.</li>
<li>If your feature is stochastic/ has non-deterministic behavior, you should show examples of different random outputs.</li>
<li>If your feature is a performance improvement, you should show examples of the runtime difference with/without your feature (and be prepared to reproduce these timing numbers in your mentor meeting, if asked).</li>
</ul><p>You should include these test cases in your submission template under the &quot;Extra Credit&quot; section. If you do not include test cases for your extra features, or if your test cases don&#x27;t sufficiently demonstrate their functionality, you will not receive credit for them.</p></div>
<p>All of the extra credit options from <a href="/projects/ray/1#extra-credit">Intersect</a> or <a href="/projects/ray/2#extra-credit">Illuminate</a> are also valid options here (provided you haven&#x27;t already done them).
In addition, you can consider the following options (or come up with your own ideas):</p>
<ul>
<li><strong>Cache pre-computed mipmaps (3 points)</strong>: Develop a scheme to save your mipmaps to disk and re-use them when rendering the same scene multiple times (e.g. from different camera angles)</li>
<li><strong>Adaptive supersampling (up to 5 points)</strong>: In the <a href="#adaptive-sampling-extra-credit">Adaptive Sampling</a> section above, we described one possible approach to adaptive sampling. You are welcome to implement that approach, or come up with your own.</li>
<li><strong>Quasi-Monte Carlo sampling (up to 5 points)</strong>: Implement a <a href="https://en.wikipedia.org/wiki/Quasi-Monte_Carlo_method" target="_blank" rel="noopener noreferrer">low-discrepancy sampling pattern</a> (e.g. Halton, Hammersley, or Sobol sequences) for supersampling.</li>
<li><strong>Better pre-filtering for mipmap generation (up to 4 points)</strong>: Use a better filter than a triangle filter for downsampling when generating mipmaps. You can use a Gaussian filter, a <a href="https://en.wikipedia.org/wiki/Lanczos_resampling" target="_blank" rel="noopener noreferrer">Lanczos filter</a>, or any other filter of your choice.</li>
<li><strong>Better filtering for render-time texture sampling (up to 4 points)</strong>: When sampling a value from a given mipmap level, use a better filter than bilinear filtering. You can use <a href="https://en.wikipedia.org/wiki/Bicubic_interpolation" target="_blank" rel="noopener noreferrer">bicubic filtering</a>, a Gaussian filter, or any other filter of your choice.</li>
<li><strong>Anisotropic filtering (up to 15 points)</strong>: Implement a method for <a href="https://en.wikipedia.org/wiki/Anisotropic_filtering" target="_blank" rel="noopener noreferrer">anisotropic</a> (i.e. direction-varying) texture filtering. Ripmaps, summed-area tables, and mipmap multisampling are all described briefly in Section 5.2 of <a href="https://research.cs.wisc.edu/graphics/Courses/559-f2003/Articles/texturing.pdf" target="_blank" rel="noopener noreferrer">this book chapter</a>. Elliptical weighted averaging (EWA) is often considered the &quot;gold standard&quot; for anisotropic texture filtering. It is hard to find a good reference for it; <a href="https://www.cs.cornell.edu/courses/cs5625/2016sp/slides/08tex-samp.pdf" target="_blank" rel="noopener noreferrer">these slides</a> introduce it at a high-level, and the approach was originally introduced in Paul Heckbert&#x27;s <a href="https://www.cs.cmu.edu/~ph/texfund/texfund.pdf" target="_blank" rel="noopener noreferrer">masters thesis (Section 3.5.8)</a>.</li>
<li><strong>Full ray differentials (10 points)</strong>: Implement tracking of ray differentials for correct ray footprint determination through reflections (and refractions, if you implemented that as extra credit in the previous project). The <a href="https://graphics.stanford.edu/papers/trd/trd.pdf" target="_blank" rel="noopener noreferrer">original paper</a> on ray differentials is a helpful reference.</li>
<li><strong>Cone tracing</strong>: Cone tracing is a geometry-based (as opposed to calculus-based) approach to determining ray footprints. Section 20.3.4 of <a href="https://www.realtimerendering.com/raytracinggems/unofficial_RayTracingGems_v1.9.pdf" target="_blank" rel="noopener noreferrer">this book chapter</a> provides a good reference.<!-- -->
<ul>
<li>Cone tracing for eye rays <strong>(up 5 points)</strong></li>
<li>Cone tracing for eye rays &amp; recursive rays <strong>(up to 15 points)</strong></li>
</ul>
</li>
</ul>
<div class="task-no-number-callout callout"><p>CS 1234/2230 students must attempt at least <strong>14 points</strong> of extra credit, which must include an implementation of full ray differentials for recursive reflection rays.</p></div>
<h2 id="tips--hints"><a href="#tips--hints">Tips &amp; Hints</a></h2>
<ul>
<li>When implementing mipmapping, we <em>highly recommend</em> that you visualize the mipmap levels you are generating to ensure that they look sensible (i.e. like downsampled versions of the original texture). If you store your mipmaps as <code>QImage</code>s, you can easily save them to disk using <code>QImage::save(filename)</code>, where <code>filename</code> is a string containing the path to the file you want to save to. You can use a naming scheme like <code>texture_mip_0.png</code>, <code>texture_mip_1.png</code>, etc. to keep track of the different levels.</li>
<li>A good way to check whether your ray footprint calculation (and thus mipmap level determination) is working correctly is to color ray intersections by mipmap level. For example, you can set the color of an intersection to be a grayscale value between <span class="math math-inline"><mjx-container className="MathJax" jax="SVG"><svg style="vertical-align:-0.05ex" xmlns="http://www.w3.org/2000/svg" width="1.131ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 500 688" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-3-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><use data-c="30" xlink:href="#MJX-3-TEX-N-30"></use></g></g></g></svg></mjx-container></span> and <span class="math math-inline"><mjx-container className="MathJax" jax="SVG"><svg style="vertical-align:-1.033ex" xmlns="http://www.w3.org/2000/svg" width="4.323ex" height="3.017ex" role="img" focusable="false" viewBox="0 -877 1910.7 1333.5" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-4-TEX-I-1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path><path id="MJX-4-TEX-N-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-4-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJX-4-TEX-N-78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mi" transform="translate(714.6,394) scale(0.707)"><use data-c="1D43F" xlink:href="#MJX-4-TEX-I-1D43F"></use></g><g data-mml-node="msub" transform="translate(220,-345) scale(0.707)"><g data-mml-node="mi"><use data-c="1D43F" xlink:href="#MJX-4-TEX-I-1D43F"></use></g><g data-mml-node="mtext" transform="translate(714,-150) scale(0.707)"><use data-c="6D" xlink:href="#MJX-4-TEX-N-6D"></use><use data-c="61" xlink:href="#MJX-4-TEX-N-61" transform="translate(833,0)"></use><use data-c="78" xlink:href="#MJX-4-TEX-N-78" transform="translate(1333,0)"></use></g></g><rect width="1670.7" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span>, where <span class="math math-inline"><mjx-container className="MathJax" jax="SVG"><svg style="vertical-align:0" xmlns="http://www.w3.org/2000/svg" width="1.541ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 681 683" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-5-TEX-I-1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D43F" xlink:href="#MJX-5-TEX-I-1D43F"></use></g></g></g></svg></mjx-container></span> is the mipmap level used for that intersection, and <span class="math math-inline"><mjx-container className="MathJax" jax="SVG"><svg style="vertical-align:-0.357ex" xmlns="http://www.w3.org/2000/svg" width="4.706ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 2079.9 840.8" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-6-TEX-I-1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path><path id="MJX-6-TEX-N-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-6-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJX-6-TEX-N-78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D43F" xlink:href="#MJX-6-TEX-I-1D43F"></use></g><g data-mml-node="mtext" transform="translate(714,-150) scale(0.707)"><use data-c="6D" xlink:href="#MJX-6-TEX-N-6D"></use><use data-c="61" xlink:href="#MJX-6-TEX-N-61" transform="translate(833,0)"></use><use data-c="78" xlink:href="#MJX-6-TEX-N-78" transform="translate(1333,0)"></use></g></g></g></g></svg></mjx-container></span> is the maximum mipmap level for that texture.</li>
</ul>
<!-- -->
<!-- -->
<h2 id="milestones"><a href="#milestones">Milestones</a></h2>
<p>Although how you approach the steps of the project is entirely up to you, we have provided a rough milestone of steps to help you code incrementally. Since this is a just an outline, please double check the <a href="/projects/ray/3#requirements">submission requirements</a> to ensure you have completed all necessary functionalities.</p>
<p><strong>Week 1</strong>:</p>
<ul>
<li>Implement supersampling (regular grid, random, and stratified)</li>
<li>Think about how you plan to implement mipmapping (e.g. where each of the parts of the implementation will go in your codebase, what data structures you&#x27;ll use to store mipmaps, how the interfaces to your existing code will change, etc.)</li>
<li>Implement bilinear filtering for texture sampling.</li>
<li>Start working on image downsampling. This is the biggest single chunk of work in the whole project, so don&#x27;t save it until the last minute!</li>
</ul>
<p><strong>Week 2</strong>:</p>
<ul>
<li>Finish image downsampling</li>
<li>Implement mipmap generation</li>
<li>Implement determining mipmap levels at render time for eye rays</li>
<li>Implement trilinear filtering</li>
</ul>
<h2 id="submission"><a href="#submission">Submission</a></h2>
<p>Submit your GitHub repo and commit ID for this project to the &quot;Project 4: Antialias&quot; assignment on Gradescope.</p>
<p>Your repo should include a submission template file in Markdown format with the filename <code>submission-antialias.md</code>. We provide the exact scenefiles
you should use to generate the outputs. You should also list some basic information about your design choices, the names of students you collaborated with, any
known bugs, and the extra credit you&#x27;ve implemented.</p>
<p>For extra credit, please describe what you&#x27;ve done and point out the related part of your code. If you implement any extra features that requires you to add a parameter for <code>QSettings.ini</code> and <code>RayTracer::Config</code>, please also document it accordingly so that the TAs won&#x27;t miss anything when grading your assignment. You must also include test cases (usually, videos or images in the style of the output comparison section) that demonstrate your extra credit features.</p>
<hr class="footer-hr"/><p class="footer-p">Please let us know if you find any mistakes, inconsistencies, or confusing language in this or any other CS 1230 document by filling out our <a href="https://forms.gle/ZYY519pzSvu8YaZK6" target="_blank">anonymous feedback form</a>.</p><style>
mjx-container[jax=&quot;SVG&quot;] {
  direction: ltr;
}

mjx-container[jax=&quot;SVG&quot;] &gt; svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax=&quot;SVG&quot;] &gt; svg a {
  fill: blue;
  stroke: blue;
}

mjx-container[jax=&quot;SVG&quot;][display=&quot;true&quot;] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax=&quot;SVG&quot;][display=&quot;true&quot;][width=&quot;full&quot;] {
  display: flex;
}

mjx-container[jax=&quot;SVG&quot;][justify=&quot;left&quot;] {
  text-align: left;
}

mjx-container[jax=&quot;SVG&quot;][justify=&quot;right&quot;] {
  text-align: right;
}

g[data-mml-node=&quot;merror&quot;] &gt; g {
  fill: red;
  stroke: red;
}

g[data-mml-node=&quot;merror&quot;] &gt; rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node=&quot;mtable&quot;] &gt; line[data-line], svg[data-table] &gt; g &gt; line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node=&quot;mtable&quot;] &gt; rect[data-frame], svg[data-table] &gt; g &gt; rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node=&quot;mtable&quot;] &gt; .mjx-dashed, svg[data-table] &gt; g &gt; .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node=&quot;mtable&quot;] &gt; .mjx-dotted, svg[data-table] &gt; g &gt; .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node=&quot;mtable&quot;] &gt; g &gt; svg {
  overflow: visible;
}

[jax=&quot;SVG&quot;] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax=&quot;SVG&quot;] mjx-tool &gt; mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool &gt; mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node=&quot;maction&quot;][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax=&quot;SVG&quot;] path[data-c], mjx-container[jax=&quot;SVG&quot;] use[data-c] {
  stroke-width: 3;
}
</style></main></div>
        </div>
      <script id="vite-plugin-ssr_pageContext" type="application/json">{"pageContext":{"_pageId":"/pages/projects/ray/3"}}</script><script type="module" src="/assets/entry-client-routing.e2287df8.js" async></script><link rel="modulepreload" as="script" type="text/javascript" href="/assets/pages/projects/ray/3.page.5cccab9f.js"><link rel="modulepreload" as="script" type="text/javascript" href="/assets/chunk-b0d73203.js"><link rel="modulepreload" as="script" type="text/javascript" href="/assets/chunk-e3efcf8b.js"><link rel="modulepreload" as="script" type="text/javascript" href="/assets/chunk-82f9daf4.js"><link rel="modulepreload" as="script" type="text/javascript" href="/assets/renderer/_default.page.client.b5b9245b.js"><link rel="modulepreload" as="script" type="text/javascript" href="/assets/entry-client-routing.e2287df8.js"><link rel="modulepreload" as="script" type="text/javascript" href="/assets/chunk-5cfa8467.js"></body>
    </html>